
import { useState, useCallback, useEffect } from 'react';
import { supabase } from '@/integrations/supabase/client';
import { useAuth } from '@/contexts/AuthContext';
import { useToast } from '@/hooks/use-toast';

interface LLMProvider {
  id: string;
  provider: string;
  api_key: string;
  is_default: boolean;
  selected_model: string | null;
}

interface DecompositionRequest {
  taskTitle: string;
  taskDescription?: string;
  tags?: string[];
  priority?: 'low' | 'medium' | 'high';
  category?: string;
  estimatedDuration?: number;
  context?: string;
}

interface SubtaskData {
  title: string;
  description: string;
  estimatedDuration?: number;
  priority?: 'low' | 'medium' | 'high';
  order?: number;
}

interface DecompositionResult {
  success: boolean;
  subtasks: SubtaskData[];
  error?: string;
}

export const useLLMManager = () => {
  const { user } = useAuth();
  const { toast } = useToast();
  const [providers, setProviders] = useState<LLMProvider[]>([]);
  const [defaultProvider, setDefaultProvider] = useState<LLMProvider | null>(null);
  const [isLoading, setIsLoading] = useState(false);

  useEffect(() => {
    if (user) {
      loadProviders();
    }
  }, [user]);

  const loadProviders = async () => {
    try {
      const { data, error } = await supabase
        .from('user_llm_api_keys')
        .select('*')
        .eq('user_id', user?.id);

      if (error) throw error;

      setProviders(data || []);
      const defaultProv = data?.find(p => p.is_default) || null;
      setDefaultProvider(defaultProv);

      // Fallback sur localStorage si pas de donn√©es Supabase
      if (!data || data.length === 0) {
        const localKeys = JSON.parse(localStorage.getItem('llm_api_keys') || '{}');
        if (Object.keys(localKeys).length > 0) {
          const firstProvider = Object.keys(localKeys)[0];
          setDefaultProvider({
            id: 'local',
            provider: firstProvider,
            api_key: localKeys[firstProvider],
            is_default: true,
            selected_model: null
          });
        }
      }
    } catch (error) {
      console.error('Erreur chargement fournisseurs LLM:', error);
      
      // Fallback sur localStorage
      const localKeys = JSON.parse(localStorage.getItem('llm_api_keys') || '{}');
      if (Object.keys(localKeys).length > 0) {
        const firstProvider = Object.keys(localKeys)[0];
        setDefaultProvider({
          id: 'local',
          provider: firstProvider,
          api_key: localKeys[firstProvider],
          is_default: true,
          selected_model: null
        });
      }
    }
  };

  const decomposeTaskWithAI = useCallback(async (
    request: DecompositionRequest
  ): Promise<DecompositionResult> => {
    if (!defaultProvider) {
      return {
        success: false,
        subtasks: [],
        error: 'Aucun fournisseur LLM configur√© par d√©faut'
      };
    }

    setIsLoading(true);
    try {
      // Prompt ultra-strict pour forcer la cr√©ation de multiples sous-t√¢ches
      const prompt = `R√àGLES STRICTES √Ä RESPECTER ABSOLUMENT :
1. Tu DOIS cr√©er EXACTEMENT entre 4 et 8 sous-t√¢ches (jamais moins de 4, jamais plus de 8)
2. R√©ponds UNIQUEMENT en JSON valide, AUCUN autre texte
3. Chaque sous-t√¢che doit √™tre sp√©cifique et actionnable
4. Ordonne les sous-t√¢ches logiquement

T√ÇCHE PRINCIPALE :
Titre: "${request.taskTitle}"
${request.taskDescription ? `Description: "${request.taskDescription}"` : ''}
${request.estimatedDuration ? `Dur√©e totale: ${request.estimatedDuration} minutes` : ''}
${request.priority ? `Priorit√©: ${request.priority}` : ''}
${request.category ? `Cat√©gorie: ${request.category}` : ''}

ANALYSE REQUISE :
- Divise cette t√¢che en √©tapes logiques et s√©quentielles
- Chaque √©tape doit prendre 15-60 minutes
- Assure-toi que toutes les √©tapes sont n√©cessaires

FORMAT JSON OBLIGATOIRE (AUCUN AUTRE TEXTE) :
{
  "subtasks": [
    {
      "title": "√âtape 1 - Titre pr√©cis",
      "description": "Description d√©taill√©e des actions √† effectuer",
      "estimatedDuration": 45,
      "priority": "high",
      "order": 1
    },
    {
      "title": "√âtape 2 - Titre pr√©cis",
      "description": "Description d√©taill√©e des actions √† effectuer",
      "estimatedDuration": 30,
      "priority": "medium",
      "order": 2
    },
    {
      "title": "√âtape 3 - Titre pr√©cis",
      "description": "Description d√©taill√©e des actions √† effectuer",
      "estimatedDuration": 35,
      "priority": "medium",
      "order": 3
    },
    {
      "title": "√âtape 4 - Titre pr√©cis",
      "description": "Description d√©taill√©e des actions √† effectuer",
      "estimatedDuration": 25,
      "priority": "low",
      "order": 4
    }
  ]
}

R√âPONDS UNIQUEMENT AVEC LE JSON, RIEN D'AUTRE !`;

      let result: string;

      if (defaultProvider.provider === 'openai') {
        result = await callOpenAI(defaultProvider.api_key, prompt, defaultProvider.selected_model);
      } else if (defaultProvider.provider === 'anthropic') {
        result = await callAnthropic(defaultProvider.api_key, prompt, defaultProvider.selected_model);
      } else if (defaultProvider.provider === 'google') {
        result = await callGoogle(defaultProvider.api_key, prompt, defaultProvider.selected_model);
      } else if (defaultProvider.provider === 'deepseek') {
        result = await callDeepSeek(defaultProvider.api_key, prompt, defaultProvider.selected_model);
      } else if (defaultProvider.provider === 'openrouter') {
        result = await callOpenRouter(defaultProvider.api_key, prompt, defaultProvider.selected_model);
      } else if (defaultProvider.provider === 'xgrok') {
        result = await callXGrok(defaultProvider.api_key, prompt, defaultProvider.selected_model);
      } else {
        throw new Error(`Fournisseur ${defaultProvider.provider} non support√©`);
      }

      console.log('ü§ñ R√©ponse brute de l\'IA:', result);

      // Nettoyage et parsing plus robuste
      let parsedResult;
      try {
        // Nettoyer agressivement la r√©ponse
        let cleanedResult = result.trim();
        
        // Enlever les backticks markdown
        cleanedResult = cleanedResult.replace(/```json\s*/g, '').replace(/```\s*/g, '');
        
        // Enlever tout texte avant le premier {
        const jsonStart = cleanedResult.indexOf('{');
        if (jsonStart > 0) {
          cleanedResult = cleanedResult.substring(jsonStart);
        }
        
        // Enlever tout texte apr√®s le dernier }
        const jsonEnd = cleanedResult.lastIndexOf('}');
        if (jsonEnd > 0) {
          cleanedResult = cleanedResult.substring(0, jsonEnd + 1);
        }
        
        console.log('üßπ JSON nettoy√©:', cleanedResult);
        
        parsedResult = JSON.parse(cleanedResult);
        
        // Validation stricte
        if (!parsedResult.subtasks || !Array.isArray(parsedResult.subtasks)) {
          throw new Error('Pas de propri√©t√© subtasks ou pas un tableau');
        }

        if (parsedResult.subtasks.length < 3) {
          throw new Error(`Pas assez de sous-t√¢ches : ${parsedResult.subtasks.length}`);
        }

        // Limiter √† 8 sous-t√¢ches max
        if (parsedResult.subtasks.length > 8) {
          parsedResult.subtasks = parsedResult.subtasks.slice(0, 8);
        }

        // Valider et nettoyer chaque sous-t√¢che
        parsedResult.subtasks = parsedResult.subtasks.map((subtask: any, index: number) => {
          if (!subtask.title || typeof subtask.title !== 'string') {
            throw new Error(`Sous-t√¢che ${index + 1} : titre manquant`);
          }
          
          return {
            title: subtask.title.trim(),
            description: subtask.description || `Sous-t√¢che ${index + 1} pour: ${request.taskTitle}`,
            estimatedDuration: typeof subtask.estimatedDuration === 'number' ? 
              Math.max(5, Math.min(120, subtask.estimatedDuration)) : 
              (request.estimatedDuration ? Math.round(request.estimatedDuration / parsedResult.subtasks.length) : 30),
            priority: ['low', 'medium', 'high'].includes(subtask.priority) ? 
              subtask.priority : request.priority || 'medium',
            order: typeof subtask.order === 'number' ? subtask.order : index + 1
          };
        });

        // Trier par ordre
        parsedResult.subtasks.sort((a: SubtaskData, b: SubtaskData) => (a.order || 0) - (b.order || 0));

      } catch (parseError) {
        console.error('‚ùå Erreur parsing JSON:', parseError);
        console.log('üîÑ Cr√©ation de sous-t√¢ches par d√©faut...');
        
        // Cr√©er des sous-t√¢ches par d√©faut bas√©es sur le titre
        const baseTitle = request.taskTitle;
        const defaultSubtasks = [
          { title: `${baseTitle} - Analyse et planification`, description: 'Analyser les exigences et √©tablir un plan d√©taill√©' },
          { title: `${baseTitle} - Pr√©paration des ressources`, description: 'Rassembler tous les outils et mat√©riaux n√©cessaires' },
          { title: `${baseTitle} - Ex√©cution principale`, description: 'R√©aliser la partie principale du travail' },
          { title: `${baseTitle} - Contr√¥le qualit√©`, description: 'V√©rifier la conformit√© et la qualit√© du r√©sultat' },
          { title: `${baseTitle} - Finalisation`, description: 'Terminer et documenter le travail accompli' }
        ];
        
        parsedResult = { 
          subtasks: defaultSubtasks.map((subtask, index) => ({
            ...subtask,
            estimatedDuration: request.estimatedDuration ? 
              Math.round(request.estimatedDuration / defaultSubtasks.length) : 30,
            priority: request.priority || 'medium',
            order: index + 1
          }))
        };
      }

      console.log(`‚úÖ ${parsedResult.subtasks.length} sous-t√¢ches g√©n√©r√©es:`, parsedResult.subtasks);

      return {
        success: true,
        subtasks: parsedResult.subtasks
      };
    } catch (error) {
      console.error('‚ùå Erreur d√©composition IA:', error);
      return {
        success: false,
        subtasks: [],
        error: error instanceof Error ? error.message : 'Erreur inconnue'
      };
    } finally {
      setIsLoading(false);
    }
  }, [defaultProvider]);

  const callOpenAI = async (apiKey: string, prompt: string, selectedModel?: string | null): Promise<string> => {
    const model = selectedModel || 'gpt-4o';
    
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model,
        messages: [
          {
            role: 'system',
            content: 'Vous √™tes un assistant sp√©cialis√© dans la d√©composition de t√¢ches. R√©pondez uniquement en JSON valide.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 500,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`Erreur OpenAI: ${errorData.error?.message || response.status}`);
    }

    const data = await response.json();
    return data.choices[0]?.message?.content || '';
  };

  const callAnthropic = async (apiKey: string, prompt: string, selectedModel?: string | null): Promise<string> => {
    const model = selectedModel || 'claude-3-5-sonnet-20241022';
    
    const response = await fetch('https://api.anthropic.com/v1/messages', {
      method: 'POST',
      headers: {
        'x-api-key': apiKey,
        'Content-Type': 'application/json',
        'anthropic-version': '2023-06-01',
      },
      body: JSON.stringify({
        model,
        max_tokens: 500,
        messages: [
          {
            role: 'user',
            content: prompt
          }
        ],
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`Erreur Anthropic: ${errorData.error?.message || response.status}`);
    }

    const data = await response.json();
    return data.content[0]?.text || '';
  };

  const callGoogle = async (apiKey: string, prompt: string, selectedModel?: string | null): Promise<string> => {
    const model = selectedModel || 'gemini-2.0-flash-exp';
    
    const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        contents: [
          {
            parts: [
              {
                text: prompt
              }
            ]
          }
        ],
        generationConfig: {
          maxOutputTokens: 500,
          temperature: 0.7,
        }
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`Erreur Google: ${errorData.error?.message || response.status}`);
    }

    const data = await response.json();
    return data.candidates[0]?.content?.parts[0]?.text || '';
  };

  const callDeepSeek = async (apiKey: string, prompt: string, selectedModel?: string | null): Promise<string> => {
    const model = selectedModel || 'deepseek-chat';
    
    const response = await fetch('https://api.deepseek.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model,
        messages: [
          {
            role: 'system',
            content: 'Vous √™tes un assistant sp√©cialis√© dans la d√©composition de t√¢ches. R√©pondez uniquement en JSON valide.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 500,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`Erreur DeepSeek: ${errorData.error?.message || response.status}`);
    }

    const data = await response.json();
    return data.choices[0]?.message?.content || '';
  };

  const callOpenRouter = async (apiKey: string, prompt: string, selectedModel?: string | null): Promise<string> => {
    const model = selectedModel || 'deepseek/deepseek-r1';
    
    const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
        'HTTP-Referer': window.location.origin,
      },
      body: JSON.stringify({
        model,
        messages: [
          {
            role: 'system',
            content: 'Vous √™tes un assistant sp√©cialis√© dans la d√©composition de t√¢ches. R√©pondez uniquement en JSON valide.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 500,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`Erreur OpenRouter: ${errorData.error?.message || response.status}`);
    }

    const data = await response.json();
    return data.choices[0]?.message?.content || '';
  };

  const callXGrok = async (apiKey: string, prompt: string, selectedModel?: string | null): Promise<string> => {
    const model = selectedModel || 'grok-beta';
    
    const response = await fetch('https://api.x.ai/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        model,
        messages: [
          {
            role: 'system',
            content: 'Vous √™tes un assistant sp√©cialis√© dans la d√©composition de t√¢ches. R√©pondez uniquement en JSON valide.'
          },
          {
            role: 'user',
            content: prompt
          }
        ],
        max_tokens: 500,
        temperature: 0.7,
      }),
    });

    if (!response.ok) {
      const errorData = await response.json();
      throw new Error(`Erreur X/Grok: ${errorData.error?.message || response.status}`);
    }

    const data = await response.json();
    return data.choices[0]?.message?.content || '';
  };

  return {
    providers,
    defaultProvider,
    decomposeTaskWithAI,
    isLoading,
    hasConfiguredProvider: !!defaultProvider,
    reloadProviders: loadProviders,
  };
};
